batch_size: 8
model:
  name: TinyLlama/TinyLlama-1.1B-Chat-v1.0
  layer_index: 12
  max_seq_len: 32         # ðŸ‘ˆ NEW: limit token length
  pad_to_max: true         # ðŸ‘ˆ NEW: pad to exactly 128

prompts:
  dataset: ernanhughes/openorca-1k-short
  split: train
  limit: 1000
  text_column: question  # Optional; weâ€™ll build full prompt from system_prompt + question

sparse_autoencoder: 
  path: sae_models/layer_12
  train_if_missing: true
  config: configs/sae/tinyllama-tinyllama-1.1b-chat-v1.0-layer11.yaml

database:
  uri: postgresql://reasoning:reasoning@localhost:5432/reasoning
